{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6ac136",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-14T16:49:56.583247Z",
     "iopub.status.busy": "2024-06-14T16:49:56.582733Z",
     "iopub.status.idle": "2024-06-14T16:49:57.928780Z",
     "shell.execute_reply": "2024-06-14T16:49:57.927170Z"
    },
    "papermill": {
     "duration": 1.356194,
     "end_time": "2024-06-14T16:49:57.931946",
     "exception": false,
     "start_time": "2024-06-14T16:49:56.575752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f16e2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:49:57.946031Z",
     "iopub.status.busy": "2024-06-14T16:49:57.945406Z",
     "iopub.status.idle": "2024-06-14T16:50:16.984611Z",
     "shell.execute_reply": "2024-06-14T16:50:16.982284Z"
    },
    "papermill": {
     "duration": 19.050692,
     "end_time": "2024-06-14T16:50:16.988705",
     "exception": false,
     "start_time": "2024-06-14T16:49:57.938013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 16:50:02.815691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-14 16:50:02.815968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-14 16:50:03.045206: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/tmp/ipykernel_19/604412195.py:20: FutureWarning: data_manager option is deprecated and will be removed in a future version. Only the BlockManager will be available.\n",
      "  pd.reset_option('all')\n",
      "/tmp/ipykernel_19/604412195.py:20: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  pd.reset_option('all')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# A library for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2  # Import l2 regularization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Output of plotting commands is displayed inline within the Jupyter notebook.\n",
    "%matplotlib inline  \n",
    "\n",
    "# Set a seed so that the results are consistent.\n",
    "np.random.seed(3) \n",
    "# Resets the options\n",
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e4b6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.001501Z",
     "iopub.status.busy": "2024-06-14T16:50:17.000609Z",
     "iopub.status.idle": "2024-06-14T16:50:17.010165Z",
     "shell.execute_reply": "2024-06-14T16:50:17.008730Z"
    },
    "papermill": {
     "duration": 0.018969,
     "end_time": "2024-06-14T16:50:17.012906",
     "exception": false,
     "start_time": "2024-06-14T16:50:16.993937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078aa2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.025603Z",
     "iopub.status.busy": "2024-06-14T16:50:17.025157Z",
     "iopub.status.idle": "2024-06-14T16:50:17.032281Z",
     "shell.execute_reply": "2024-06-14T16:50:17.030711Z"
    },
    "papermill": {
     "duration": 0.01897,
     "end_time": "2024-06-14T16:50:17.036808",
     "exception": false,
     "start_time": "2024-06-14T16:50:17.017838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_full(x):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930b6990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.049585Z",
     "iopub.status.busy": "2024-06-14T16:50:17.049144Z",
     "iopub.status.idle": "2024-06-14T16:50:17.056957Z",
     "shell.execute_reply": "2024-06-14T16:50:17.055203Z"
    },
    "papermill": {
     "duration": 0.017791,
     "end_time": "2024-06-14T16:50:17.059914",
     "exception": false,
     "start_time": "2024-06-14T16:50:17.042123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_columns(x):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(x)\n",
    "    pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651638a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.073961Z",
     "iopub.status.busy": "2024-06-14T16:50:17.073337Z",
     "iopub.status.idle": "2024-06-14T16:50:17.334739Z",
     "shell.execute_reply": "2024-06-14T16:50:17.333278Z"
    },
    "papermill": {
     "duration": 0.27244,
     "end_time": "2024-06-14T16:50:17.338028",
     "exception": false,
     "start_time": "2024-06-14T16:50:17.065588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "print(breast_cancer['DESCR'])\n",
    "adv = pd.DataFrame(breast_cancer['data'], columns=breast_cancer['feature_names'])\n",
    "adv['target'] = breast_cancer['target']\n",
    "\n",
    "display_columns(adv)\n",
    "null_counts = adv.isnull().sum()\n",
    "print_full(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fddcb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.353058Z",
     "iopub.status.busy": "2024-06-14T16:50:17.352612Z",
     "iopub.status.idle": "2024-06-14T16:50:17.402606Z",
     "shell.execute_reply": "2024-06-14T16:50:17.401324Z"
    },
    "papermill": {
     "duration": 0.061339,
     "end_time": "2024-06-14T16:50:17.405509",
     "exception": false,
     "start_time": "2024-06-14T16:50:17.344170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>2.489734</td>\n",
       "      <td>-0.565265</td>\n",
       "      <td>2.833031</td>\n",
       "      <td>2.487578</td>\n",
       "      <td>-0.214002</td>\n",
       "      <td>1.316862</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.660820</td>\n",
       "      <td>1.148757</td>\n",
       "      <td>0.907083</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>-0.876244</td>\n",
       "      <td>0.263327</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>-0.605351</td>\n",
       "      <td>-0.692926</td>\n",
       "      <td>-0.440780</td>\n",
       "      <td>0.260162</td>\n",
       "      <td>-0.805450</td>\n",
       "      <td>-0.099444</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>1.228676</td>\n",
       "      <td>-0.780083</td>\n",
       "      <td>0.850928</td>\n",
       "      <td>1.181336</td>\n",
       "      <td>-0.297005</td>\n",
       "      <td>0.814974</td>\n",
       "      <td>0.213076</td>\n",
       "      <td>1.424827</td>\n",
       "      <td>0.237036</td>\n",
       "      <td>0.293559</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>0.326373</td>\n",
       "      <td>-0.110409</td>\n",
       "      <td>0.286593</td>\n",
       "      <td>-0.288378</td>\n",
       "      <td>0.689702</td>\n",
       "      <td>2.744280</td>\n",
       "      <td>0.819518</td>\n",
       "      <td>1.115007</td>\n",
       "      <td>4.732680</td>\n",
       "      <td>2.047511</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>1.270543</td>\n",
       "      <td>-0.790244</td>\n",
       "      <td>1.273189</td>\n",
       "      <td>1.190357</td>\n",
       "      <td>1.483067</td>\n",
       "      <td>-0.048520</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>1.144205</td>\n",
       "      <td>-0.361092</td>\n",
       "      <td>0.499328</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0       0     1.097064     -2.073335        1.269934   0.984375   \n",
       "1       0     1.829821     -0.353632        1.685955   1.908708   \n",
       "2       0     1.579888      0.456187        1.566503   1.558884   \n",
       "3       0    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4       0     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0         1.568466          3.283515        2.652874             2.532475   \n",
       "1        -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2         0.942210          1.052926        1.363478             2.037231   \n",
       "3         3.283553          3.402909        1.915897             1.451707   \n",
       "4         0.280372          0.539340        1.371011             1.428493   \n",
       "\n",
       "   mean symmetry  mean fractal dimension  radius error  texture error  \\\n",
       "0       2.217515                2.255747      2.489734      -0.565265   \n",
       "1       0.001392               -0.868652      0.499255      -0.876244   \n",
       "2       0.939685               -0.398008      1.228676      -0.780083   \n",
       "3       2.867383                4.910919      0.326373      -0.110409   \n",
       "4      -0.009560               -0.562450      1.270543      -0.790244   \n",
       "\n",
       "   perimeter error  area error  smoothness error  compactness error  \\\n",
       "0         2.833031    2.487578         -0.214002           1.316862   \n",
       "1         0.263327    0.742402         -0.605351          -0.692926   \n",
       "2         0.850928    1.181336         -0.297005           0.814974   \n",
       "3         0.286593   -0.288378          0.689702           2.744280   \n",
       "4         1.273189    1.190357          1.483067          -0.048520   \n",
       "\n",
       "   concavity error  concave points error  symmetry error  \\\n",
       "0         0.724026              0.660820        1.148757   \n",
       "1        -0.440780              0.260162       -0.805450   \n",
       "2         0.213076              1.424827        0.237036   \n",
       "3         0.819518              1.115007        4.732680   \n",
       "4         0.828471              1.144205       -0.361092   \n",
       "\n",
       "   fractal dimension error  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.907083      1.886690      -1.359293         2.303601   \n",
       "1                -0.099444      1.805927      -0.369203         1.535126   \n",
       "2                 0.293559      1.511870      -0.023974         1.347475   \n",
       "3                 2.047511     -0.281464       0.133984        -0.249939   \n",
       "4                 0.499328      1.298575      -1.466770         1.338539   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0    2.001237          1.307686           2.616665         2.109526   \n",
       "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2    1.456285          0.527407           1.082932         0.854974   \n",
       "3   -0.550021          3.394275           3.893397         1.989588   \n",
       "4    1.220724          0.220556          -0.313395         0.613179   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0              2.296076        2.750622                 1.937015  \n",
       "1              1.087084       -0.243890                 0.281190  \n",
       "2              1.955000        1.152255                 0.201391  \n",
       "3              2.175786        6.046041                 4.935010  \n",
       "4              0.729259       -0.868353                -0.397100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = adv.copy()\n",
    "numerical_columns = df.columns[:-1]  # All columns except the last one (target)\n",
    "target_column = 'target'\n",
    "\n",
    "scaler_numerical = StandardScaler()\n",
    "\n",
    "df_numerical = pd.DataFrame(scaler_numerical.fit_transform(adv[numerical_columns]), columns=numerical_columns)\n",
    "\n",
    "\n",
    "\n",
    "df_combined = pd.concat([adv.drop(columns=numerical_columns), df_numerical], axis=1)\n",
    "\n",
    "\n",
    "display_columns(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91945c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.421369Z",
     "iopub.status.busy": "2024-06-14T16:50:17.420927Z",
     "iopub.status.idle": "2024-06-14T16:50:17.434407Z",
     "shell.execute_reply": "2024-06-14T16:50:17.432080Z"
    },
    "papermill": {
     "duration": 0.025546,
     "end_time": "2024-06-14T16:50:17.438378",
     "exception": false,
     "start_time": "2024-06-14T16:50:17.412832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_combined.drop(columns=[target_column])\n",
    "y = df_combined[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70022ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:17.454658Z",
     "iopub.status.busy": "2024-06-14T16:50:17.454224Z",
     "iopub.status.idle": "2024-06-14T16:50:41.389359Z",
     "shell.execute_reply": "2024-06-14T16:50:41.388032Z"
    },
    "papermill": {
     "duration": 23.945921,
     "end_time": "2024-06-14T16:50:41.392022",
     "exception": false,
     "start_time": "2024-06-14T16:50:17.446101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 - 2s - 44ms/step - accuracy: 0.3714 - loss: 0.8309 - val_accuracy: 0.3772 - val_loss: 0.7455\n",
      "Epoch 2/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.6198 - loss: 0.7048 - val_accuracy: 0.9386 - val_loss: 0.6554\n",
      "Epoch 3/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9297 - loss: 0.6314 - val_accuracy: 0.9737 - val_loss: 0.5920\n",
      "Epoch 4/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9473 - loss: 0.5737 - val_accuracy: 0.9561 - val_loss: 0.5377\n",
      "Epoch 5/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9451 - loss: 0.5224 - val_accuracy: 0.9649 - val_loss: 0.4864\n",
      "Epoch 6/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9473 - loss: 0.4727 - val_accuracy: 0.9649 - val_loss: 0.4375\n",
      "Epoch 7/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9538 - loss: 0.4270 - val_accuracy: 0.9649 - val_loss: 0.3939\n",
      "Epoch 8/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9604 - loss: 0.3872 - val_accuracy: 0.9649 - val_loss: 0.3566\n",
      "Epoch 9/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9648 - loss: 0.3536 - val_accuracy: 0.9825 - val_loss: 0.3268\n",
      "Epoch 10/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9714 - loss: 0.3265 - val_accuracy: 0.9825 - val_loss: 0.3029\n",
      "Epoch 11/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9758 - loss: 0.3039 - val_accuracy: 0.9825 - val_loss: 0.2830\n",
      "Epoch 12/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9758 - loss: 0.2856 - val_accuracy: 0.9825 - val_loss: 0.2668\n",
      "Epoch 13/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2706 - val_accuracy: 0.9825 - val_loss: 0.2539\n",
      "Epoch 14/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9802 - loss: 0.2574 - val_accuracy: 0.9825 - val_loss: 0.2419\n",
      "Epoch 15/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2469 - val_accuracy: 0.9825 - val_loss: 0.2327\n",
      "Epoch 16/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2370 - val_accuracy: 0.9825 - val_loss: 0.2238\n",
      "Epoch 17/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2288 - val_accuracy: 0.9825 - val_loss: 0.2165\n",
      "Epoch 18/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2214 - val_accuracy: 0.9825 - val_loss: 0.2100\n",
      "Epoch 19/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2151 - val_accuracy: 0.9825 - val_loss: 0.2043\n",
      "Epoch 20/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.2097 - val_accuracy: 0.9825 - val_loss: 0.1999\n",
      "Epoch 21/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.2044 - val_accuracy: 0.9825 - val_loss: 0.1951\n",
      "Epoch 22/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9802 - loss: 0.1995 - val_accuracy: 0.9825 - val_loss: 0.1912\n",
      "Epoch 23/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1962 - val_accuracy: 0.9825 - val_loss: 0.1878\n",
      "Epoch 24/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1919 - val_accuracy: 0.9912 - val_loss: 0.1840\n",
      "Epoch 25/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1880 - val_accuracy: 0.9825 - val_loss: 0.1804\n",
      "Epoch 26/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1852 - val_accuracy: 0.9825 - val_loss: 0.1790\n",
      "Epoch 27/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1825 - val_accuracy: 0.9825 - val_loss: 0.1759\n",
      "Epoch 28/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1797 - val_accuracy: 0.9912 - val_loss: 0.1728\n",
      "Epoch 29/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1773 - val_accuracy: 0.9825 - val_loss: 0.1695\n",
      "Epoch 30/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1747 - val_accuracy: 0.9912 - val_loss: 0.1688\n",
      "Epoch 31/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1731 - val_accuracy: 0.9912 - val_loss: 0.1673\n",
      "Epoch 32/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1715 - val_accuracy: 0.9912 - val_loss: 0.1650\n",
      "Epoch 33/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1682 - val_accuracy: 0.9912 - val_loss: 0.1638\n",
      "Epoch 34/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1667 - val_accuracy: 0.9912 - val_loss: 0.1624\n",
      "Epoch 35/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1652 - val_accuracy: 0.9825 - val_loss: 0.1602\n",
      "Epoch 36/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1638 - val_accuracy: 0.9825 - val_loss: 0.1580\n",
      "Epoch 37/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1616 - val_accuracy: 0.9912 - val_loss: 0.1572\n",
      "Epoch 38/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1604 - val_accuracy: 0.9912 - val_loss: 0.1574\n",
      "Epoch 39/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1594 - val_accuracy: 0.9912 - val_loss: 0.1557\n",
      "Epoch 40/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9824 - loss: 0.1583 - val_accuracy: 0.9912 - val_loss: 0.1543\n",
      "Epoch 41/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1567 - val_accuracy: 0.9825 - val_loss: 0.1533\n",
      "Epoch 42/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1555 - val_accuracy: 0.9912 - val_loss: 0.1524\n",
      "Epoch 43/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1546 - val_accuracy: 0.9912 - val_loss: 0.1511\n",
      "Epoch 44/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1550 - val_accuracy: 0.9912 - val_loss: 0.1506\n",
      "Epoch 45/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1533 - val_accuracy: 0.9912 - val_loss: 0.1500\n",
      "Epoch 46/140\n",
      "46/46 - 0s - 7ms/step - accuracy: 0.9824 - loss: 0.1520 - val_accuracy: 0.9825 - val_loss: 0.1483\n",
      "Epoch 47/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1512 - val_accuracy: 0.9912 - val_loss: 0.1486\n",
      "Epoch 48/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1500 - val_accuracy: 0.9912 - val_loss: 0.1473\n",
      "Epoch 49/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1497 - val_accuracy: 0.9825 - val_loss: 0.1460\n",
      "Epoch 50/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1483 - val_accuracy: 0.9825 - val_loss: 0.1460\n",
      "Epoch 51/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1480 - val_accuracy: 0.9912 - val_loss: 0.1453\n",
      "Epoch 52/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1476 - val_accuracy: 0.9912 - val_loss: 0.1452\n",
      "Epoch 53/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9868 - loss: 0.1472 - val_accuracy: 0.9912 - val_loss: 0.1447\n",
      "Epoch 54/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.1463 - val_accuracy: 0.9825 - val_loss: 0.1429\n",
      "Epoch 55/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9824 - loss: 0.1463 - val_accuracy: 0.9912 - val_loss: 0.1440\n",
      "Epoch 56/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.1451 - val_accuracy: 0.9912 - val_loss: 0.1436\n",
      "Epoch 57/140\n",
      "46/46 - 0s - 6ms/step - accuracy: 0.9846 - loss: 0.1450 - val_accuracy: 0.9912 - val_loss: 0.1430\n",
      "Epoch 58/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1446 - val_accuracy: 0.9825 - val_loss: 0.1414\n",
      "Epoch 59/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.1454 - val_accuracy: 0.9912 - val_loss: 0.1417\n",
      "Epoch 60/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.1439 - val_accuracy: 0.9825 - val_loss: 0.1408\n",
      "Epoch 61/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1430 - val_accuracy: 0.9912 - val_loss: 0.1409\n",
      "Epoch 62/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1424 - val_accuracy: 0.9912 - val_loss: 0.1400\n",
      "Epoch 63/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.1424 - val_accuracy: 0.9912 - val_loss: 0.1395\n",
      "Epoch 64/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1421 - val_accuracy: 0.9912 - val_loss: 0.1396\n",
      "Epoch 65/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1411 - val_accuracy: 0.9912 - val_loss: 0.1397\n",
      "Epoch 66/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1408 - val_accuracy: 0.9912 - val_loss: 0.1393\n",
      "Epoch 67/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1408 - val_accuracy: 0.9912 - val_loss: 0.1393\n",
      "Epoch 68/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1402 - val_accuracy: 0.9825 - val_loss: 0.1379\n",
      "Epoch 69/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1401 - val_accuracy: 0.9912 - val_loss: 0.1394\n",
      "Epoch 70/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1396 - val_accuracy: 0.9912 - val_loss: 0.1384\n",
      "Epoch 71/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1398 - val_accuracy: 0.9912 - val_loss: 0.1381\n",
      "Epoch 72/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1391 - val_accuracy: 0.9912 - val_loss: 0.1374\n",
      "Epoch 73/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1390 - val_accuracy: 0.9825 - val_loss: 0.1376\n",
      "Epoch 74/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1388 - val_accuracy: 0.9825 - val_loss: 0.1373\n",
      "Epoch 75/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1390 - val_accuracy: 0.9825 - val_loss: 0.1369\n",
      "Epoch 76/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1387 - val_accuracy: 0.9912 - val_loss: 0.1368\n",
      "Epoch 77/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1384 - val_accuracy: 0.9912 - val_loss: 0.1380\n",
      "Epoch 78/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1381 - val_accuracy: 0.9825 - val_loss: 0.1361\n",
      "Epoch 79/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1377 - val_accuracy: 0.9912 - val_loss: 0.1372\n",
      "Epoch 80/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1378 - val_accuracy: 0.9825 - val_loss: 0.1364\n",
      "Epoch 81/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1367 - val_accuracy: 0.9912 - val_loss: 0.1371\n",
      "Epoch 82/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1368 - val_accuracy: 0.9825 - val_loss: 0.1362\n",
      "Epoch 83/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1369 - val_accuracy: 0.9825 - val_loss: 0.1361\n",
      "Epoch 84/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1363 - val_accuracy: 0.9825 - val_loss: 0.1358\n",
      "Epoch 85/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1363 - val_accuracy: 0.9912 - val_loss: 0.1355\n",
      "Epoch 86/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1369 - val_accuracy: 0.9912 - val_loss: 0.1356\n",
      "Epoch 87/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1361 - val_accuracy: 0.9912 - val_loss: 0.1363\n",
      "Epoch 88/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1366 - val_accuracy: 0.9825 - val_loss: 0.1364\n",
      "Epoch 89/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1357 - val_accuracy: 0.9825 - val_loss: 0.1350\n",
      "Epoch 90/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1364 - val_accuracy: 0.9912 - val_loss: 0.1353\n",
      "Epoch 91/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1351 - val_accuracy: 0.9912 - val_loss: 0.1346\n",
      "Epoch 92/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1350 - val_accuracy: 0.9912 - val_loss: 0.1359\n",
      "Epoch 93/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1350 - val_accuracy: 0.9912 - val_loss: 0.1351\n",
      "Epoch 94/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1353 - val_accuracy: 0.9912 - val_loss: 0.1342\n",
      "Epoch 95/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1350 - val_accuracy: 0.9912 - val_loss: 0.1343\n",
      "Epoch 96/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9824 - loss: 0.1368 - val_accuracy: 0.9912 - val_loss: 0.1351\n",
      "Epoch 97/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1356 - val_accuracy: 0.9912 - val_loss: 0.1355\n",
      "Epoch 98/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1350 - val_accuracy: 0.9825 - val_loss: 0.1345\n",
      "Epoch 99/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1348 - val_accuracy: 0.9825 - val_loss: 0.1348\n",
      "Epoch 100/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9868 - loss: 0.1344 - val_accuracy: 0.9912 - val_loss: 0.1344\n",
      "Epoch 101/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1340 - val_accuracy: 0.9912 - val_loss: 0.1341\n",
      "Epoch 102/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1340 - val_accuracy: 0.9912 - val_loss: 0.1348\n",
      "Epoch 103/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1344 - val_accuracy: 0.9912 - val_loss: 0.1341\n",
      "Epoch 104/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1341 - val_accuracy: 0.9825 - val_loss: 0.1348\n",
      "Epoch 105/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1341 - val_accuracy: 0.9912 - val_loss: 0.1340\n",
      "Epoch 106/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1341 - val_accuracy: 0.9912 - val_loss: 0.1352\n",
      "Epoch 107/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1340 - val_accuracy: 0.9912 - val_loss: 0.1334\n",
      "Epoch 108/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1334 - val_accuracy: 0.9912 - val_loss: 0.1346\n",
      "Epoch 109/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1335 - val_accuracy: 0.9912 - val_loss: 0.1336\n",
      "Epoch 110/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1339 - val_accuracy: 0.9825 - val_loss: 0.1343\n",
      "Epoch 111/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1343 - val_accuracy: 0.9912 - val_loss: 0.1341\n",
      "Epoch 112/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1335 - val_accuracy: 0.9825 - val_loss: 0.1339\n",
      "Epoch 113/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1342 - val_accuracy: 0.9912 - val_loss: 0.1336\n",
      "Epoch 114/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1348 - val_accuracy: 0.9912 - val_loss: 0.1350\n",
      "Epoch 115/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1336 - val_accuracy: 0.9912 - val_loss: 0.1349\n",
      "Epoch 116/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1338 - val_accuracy: 0.9912 - val_loss: 0.1344\n",
      "Epoch 117/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1338 - val_accuracy: 0.9912 - val_loss: 0.1343\n",
      "Epoch 118/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1347 - val_accuracy: 0.9825 - val_loss: 0.1348\n",
      "Epoch 119/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1337 - val_accuracy: 0.9825 - val_loss: 0.1330\n",
      "Epoch 120/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1333 - val_accuracy: 0.9912 - val_loss: 0.1340\n",
      "Epoch 121/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1335 - val_accuracy: 0.9912 - val_loss: 0.1333\n",
      "Epoch 122/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1327 - val_accuracy: 0.9825 - val_loss: 0.1340\n",
      "Epoch 123/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1330 - val_accuracy: 0.9825 - val_loss: 0.1336\n",
      "Epoch 124/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1347 - val_accuracy: 0.9825 - val_loss: 0.1345\n",
      "Epoch 125/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1326 - val_accuracy: 0.9912 - val_loss: 0.1333\n",
      "Epoch 126/140\n",
      "46/46 - 0s - 4ms/step - accuracy: 0.9868 - loss: 0.1328 - val_accuracy: 0.9912 - val_loss: 0.1331\n",
      "Epoch 127/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1332 - val_accuracy: 0.9825 - val_loss: 0.1335\n",
      "Epoch 128/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1329 - val_accuracy: 0.9825 - val_loss: 0.1324\n",
      "Epoch 129/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1327 - val_accuracy: 0.9825 - val_loss: 0.1329\n",
      "Epoch 130/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1341 - val_accuracy: 0.9912 - val_loss: 0.1345\n",
      "Epoch 131/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1328 - val_accuracy: 0.9825 - val_loss: 0.1331\n",
      "Epoch 132/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1328 - val_accuracy: 0.9825 - val_loss: 0.1328\n",
      "Epoch 133/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.1331 - val_accuracy: 0.9912 - val_loss: 0.1323\n",
      "Epoch 134/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1322 - val_accuracy: 0.9912 - val_loss: 0.1341\n",
      "Epoch 135/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1324 - val_accuracy: 0.9825 - val_loss: 0.1327\n",
      "Epoch 136/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1329 - val_accuracy: 0.9825 - val_loss: 0.1334\n",
      "Epoch 137/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1322 - val_accuracy: 0.9912 - val_loss: 0.1323\n",
      "Epoch 138/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1328 - val_accuracy: 0.9825 - val_loss: 0.1322\n",
      "Epoch 139/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9846 - loss: 0.1324 - val_accuracy: 0.9912 - val_loss: 0.1333\n",
      "Epoch 140/140\n",
      "46/46 - 0s - 3ms/step - accuracy: 0.9868 - loss: 0.1329 - val_accuracy: 0.9912 - val_loss: 0.1322\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.1430 \n",
      "Test Loss: 0.13223101198673248\n",
      "Test Accuracy: 0.9912280440330505\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=X_train.shape[1], activation='sigmoid', kernel_regularizer=l2(0.002)))\n",
    "model.add(Dense(8, input_dim=X_train.shape[1], activation='sigmoid', kernel_regularizer=l2(0.002)))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))) \n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=140, batch_size=10, verbose=2, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fa17a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:50:41.460912Z",
     "iopub.status.busy": "2024-06-14T16:50:41.460437Z",
     "iopub.status.idle": "2024-06-14T16:50:42.262403Z",
     "shell.execute_reply": "2024-06-14T16:50:42.261183Z"
    },
    "papermill": {
     "duration": 0.838836,
     "end_time": "2024-06-14T16:50:42.264916",
     "exception": false,
     "start_time": "2024-06-14T16:50:41.426080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=136, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 51.662855,
   "end_time": "2024-06-14T16:50:44.127057",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-14T16:49:52.464202",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
